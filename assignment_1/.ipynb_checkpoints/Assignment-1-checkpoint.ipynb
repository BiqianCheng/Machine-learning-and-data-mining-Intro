{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS171 - Winter 2020 - Assignment 1\n",
    "### Instructor: Vagelis Papalexakis\n",
    "### TA: Ekta Gujral\n",
    "\n",
    "### Credit for  Assignment 1: 5/40 points of the final grade\n",
    "\n",
    "\n",
    "In this first assignment you will explore a dataset, visualizing the dataset in various ways, and doing a preliminary analysis on the data. \n",
    "\n",
    "For this assignment we are going to use the functionality of Pandas (the library, *not* the unbearably cute animal): https://pandas.pydata.org/ in order to manipulate datasets.\n",
    "In addition to Pandas, we are going to use Matplotlib (https://matplotlib.org/) and Numpy (http://www.numpy.org/) and you may also find Seaborn (https://seaborn.pydata.org/) useful for some data visualization.\n",
    "\n",
    "Unless you are explicitly asked to *implement* a particular functionality, you may assume that you may use an existing implementation from the libraries above (or some other library that you may find, as long as you *document* it).\n",
    "\n",
    "Before you start, make sure you have installed all those packages in your local Jupyter instance, as follows:\n",
    "\n",
    "conda install numpy pandas matplotlib seaborn\n",
    "\n",
    "## Academic Integrity\n",
    "Each assignment should be done  individually. You may discuss general approaches with other students in the class, and ask questions to the TAs, but  you must only submit work that is yours . If you receive help by any external sources (other than the TA and the instructor), you must properly credit those sources, and if the help is significant, the appropriate grade reduction will be applied. If you fail to do so, the instructor and the TAs are obligated to take the appropriate actions outlined at http://conduct.ucr.edu/policies/academicintegrity.html . Please read carefully the UCR academic integrity policies included in the link.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import random as rd\n",
    "#make sure you import here everything else you may need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0: Getting real data [0%] \n",
    "\n",
    "In this assignment you are going to use data from the UCI Machine Learning repository ( https://archive.ics.uci.edu/ml/index.php ). In particular, you are going to use the famous Iris dataset: https://archive.ics.uci.edu/ml/datasets/Iris\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width           label\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label']\n",
    "data = pd.read_csv('iris.data', \n",
    "                   names = data_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Data Visualization [20%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1a: Scatterplots [10%]\n",
    "1. Plot the scatterplot of all pairs of features and color the points by class label [5%]\n",
    "2. Which pair of features is (visually) the most correlated?  [2.5%]\n",
    "3. Can you think of a reason why looking at this plot would be useful in a task where we would have to classify flowers by label? [2.5%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "features = sb.pairplot(data, hue=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:\n",
    "2. The pair of petal_length and petal_witdth is the most correlated amoung these graphs, because these two graphs could drop most amount of data point of a single line.\n",
    "3. Because it works better the way how human brains are build processes abstract information and visualize a large amounts of complex data by using charts and graphs, which helps to build a visulization for a big amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b: Boxplot and Histogram [10%]\n",
    "\n",
    "1. Plot the boxplot for each feature of the dataset (you can put all boxplots on a single figure) [4%]\n",
    "2. Plot the histogram only for petal length [4%]\n",
    "3. Does the histogram for petal length give more information than the boxplot? If so, what information? [2%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:    \n",
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "boxplot = data.boxplot(column = data_names[0:4])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_lengths_histogram = sb.histplot(x=data[\"petal_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:\n",
    "\n",
    "3. Yes, the histogram for petal length give more information than the boxplot. It gives more information such as it has clearer data distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Distance computation [40%]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a: Implement the Lp distance function [20%]\n",
    "1. Write code that implements the Lp distance function between two data points as we saw it in class [15%]\n",
    "2. Verify that it is correct by comparing it for p=2 against an existing implementation in Numpy for the two selected data points below. Note that the difference of the distances may not be exactly 0 due to numerical precision issues. [5%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def cal_lp_dist(x,y,p):\n",
    "    distance = 0\n",
    "    for i in range(len(x)):\n",
    "        distance = distance + abs(x[i]-y[i]) ** p\n",
    "    distance = distance ** (1/p)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = data.loc[12].values[:4]\n",
    "p2 = data.loc[100].values[:4]\n",
    "\n",
    "o1 = cal_lp_dist(p1,p2,2)\n",
    "o2 = np.linalg.norm(p1 - p2)\n",
    "\n",
    "print(o1)\n",
    "print(o2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b: Compute the distance matrix between all data points [20%]\n",
    "1. Compute an $N\\times N$ distance matrix between all data points (where $N$ is the number of data points) [5%]\n",
    "2. Plot the above matrix and include a colorbar. [5%]\n",
    "3. What is the minimum number of distance computations that you can do in order to populate every value of this matrix? (note: it is OK if in the first two questions you do all the $N^2$ computations) [5%]\n",
    "4. Note that the data points in your dataset are sorted by class. What do you observe in the distance matrix? [5%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "DM = np.zeros((len(data),len(data)))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        DM[i][j] = cal_lp_dist(list(data.loc[i])[:4], list(data.loc[j])[:4],2)\n",
    "        \n",
    "sb.heatmap(DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:\n",
    "3. The minimum number of distance computations that I can do is (N * N)/2, because the data on the left lower part is symmetric to the data on the right upper part, so that I need to calculate only half of the whole data table. In addition, since the data on the diagnol are known, there is no need to calculate them again, substract numbers of data on diagonal. Therefore, the final numbers of calculation would be (N * N)/2 - N.\n",
    "4. The difference between each class is significant, but the difference between alike class is almost identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Data Sampling [40%]\n",
    "\n",
    "Sometimes datasets are too big, or come in a streaming fashion, and it is impossible for us to process every single data point, so we have to resort to sampling methods. In this question, you will implement the popular \"reservoir sampling\" method, which is mostly used to obtain a uniform random sample of a data stream. Subsequently, you will experiment with sampling directly all the data and conducting stratified sampling (by class label) and observe the results in the data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3a: Reservoir Sampling [20%]\n",
    "1. Implement reservoir sampling as we saw it in class. Create a 'reservoir_sampling' function because it will be useful for the next question. [15%]\n",
    "2. Run reservoir sampling with reservoir size $M = 15$ and plot the histogram of the petal length feature for the sampled dataset [5%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def reservoir_sampling(stream,M):\n",
    "    counter = 0\n",
    "    reservoir = [None] * M\n",
    "    for counter in range(M):\n",
    "        reservoir[counter] = stream.loc[counter]\n",
    "        \n",
    "    while(counter < len(stream)):\n",
    "        counter2 = rd.randrange(counter + 1)\n",
    "        if(counter2 < M):\n",
    "            reservoir[counter2] = stream.loc[counter]\n",
    "        counter = counter + 1\n",
    "    return reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_data = pd.DataFrame(reservoir_sampling(data,15))\n",
    "sb.histplot(x=rs_data[\"petal_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3b: Stratified Sampling [20%]\n",
    "1. Implement stratified sampling by class label, and within each stratum use the reservoir sampling function you implemented. [15%]\n",
    "2. Run your stratified sampler with $M=5$ samples per class (so that we have 15 data points in total) and plot the histogram of the petal length feature for the sampled dataset [2.5%]\n",
    "3. Do you observe any difference between the stratified and the non-stratified histograms? Which one resembles the original petal length distribution more closely? In order to answer this question you may want to run both sampling procedures a few times and observe which one gives a more accurate result on average. [2.5%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def stratified_sampling(data,M):\n",
    "    labels = data[\"label\"].unique()\n",
    "    sampling_pool = pd.DataFrame(columns=data_names)\n",
    "    for label in labels:\n",
    "        sampling_pool = sampling_pool.append(reservoir_samping((data.loc[data[\"label\"] == label]), int(M/len(labels))), ignore_index=True)\n",
    "    return sampling_pool.drop(columns=\"index\")\n",
    "\n",
    "result = stratified_sampling(data,15)\n",
    "ssamping = sns.histplot(x=result[\"petal_length\"],stat=\"frequency\",binwidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straitified sampling is better than reservoir sampling because straitified sampling ensure even in each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
